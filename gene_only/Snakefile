import os
import sys
import glob
import numpy as np
import pandas as pd
import math
import sys
import random
import pickle

import dask.dataframe as dd
from dask.distributed import Client

import torch
import pyro
import pyro.distributions as dist
import pyro.distributions.constraints as constraints
from pyro.nn import PyroModule

from tqdm import tqdm
from torch.utils.data import Dataset, DataLoader

sys.path.insert(0, '/home/djl34/lab_pd/kl/git/KL')
import raklette_updated

sys.path.insert(0, '/home/djl34/lab_pd/kl/git/KL/kl_gene')
from raklette_gene import run_raklette
from raklette_gene import TSVDataset

KL_data_dir = "/home/djl34/lab_pd/kl/data"
scratch_dir = "/n/scratch3/users/d/djl34"

base_set = ["A", "C", "T", "G"]
chrom_set = [str(x) for x in range(1, 23)]
# chrom_set = ["22"]

gene_set_file = os.path.join(scratch_dir, "kl_input/enhancer_module/unique_gene.tsv")

if os.path.isfile(gene_set_file):
    df = pd.read_csv(os.path.join(scratch_dir, "kl_input/enhancer_module/unique_gene.tsv"), sep = "\t", header = None)
    gene_set = df[0]
else:
    gene_set = []
    
gene_positive_set = [x for x in gene_set if int(x) > 0]

rule all:
    input:
#         [os.path.join(scratch_dir, "kl_input/enhancer_module/" + chrom +".tsv") for chrom in chrom_set],
#         os.path.join(scratch_dir, "kl_input/enhancer_module/unique_gene.tsv"),
#         gene_set_file,
        [os.path.join(scratch_dir, "kl_input/enhancer_module/divided/gene_" + str(gene) +".tsv") for gene in gene_positive_set],
        os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants.tsv"),
        os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants_frac_0.01.tsv"),
#         os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants_frac_0.05.tsv"),
#         os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants_length.txt"),
        os.path.join(KL_data_dir, "raklette_output/kl_gene/enhancer_module/whole_genome_gene_variants_1000000_epoch_10.pkl"),
#         os.path.join(KL_data_dir, "raklette_output/kl_gene/enhancer_module/whole_genome_gene_variants_frac_0.01_epoch_1.pkl")
#         os.path.join(KL_data_dir, "raklette_output/kl_gene/enhancer_module/all_noncoding.tsv")

        
###################################### filter sites for KL analysis ######################################

rule make_tsv_files:
    input:
        os.path.join(KL_data_dir, "enhancer/{chrom}/_metadata")
    output:
        os.path.join(scratch_dir, "kl_input/enhancer_module/{chrom}.tsv")
    run:
        with Client() as client:
            
            rate = dd.read_parquet("/".join(input[0].split("/")[:-1]) + "/")
            
            print(rate.columns)
            
            rate = rate[rate["coding"] == False]
            
            rate["e_module"] = rate["e_module"].fillna(-1)
            rate["e_module"] = rate["e_module"].astype(int)
#             rate["e_module"] = rate["e_module"] - rate["e_module"].min() # set everything to 0
            rate["gene"] = rate["e_module"]
            
            include_columns = ["mu_index", "Freq_bin", "gene"]
            
            rate = rate[include_columns]
            
            rate.to_csv(output[0], sep = "\t", index = None, single_file = True)

rule get_unique_genes:
    input:
        [os.path.join(scratch_dir, "kl_input/enhancer_module/" + chrom +".tsv") for chrom in chrom_set]
    output:
        os.path.join(scratch_dir, "kl_input/enhancer_module/unique_gene.tsv")
    run:
        with Client() as client:
            rate = dd.read_csv(input[0], sep = "\t", 
                               dtype={'gene': 'int'})
            
            minimum_value = rate["gene"].min().compute()
            print(minimum_value)
            maximum_value = rate["gene"].max().compute()
            print(maximum_value)
            
            f = open(output[0], "w")
            
            for i in range(minimum_value, maximum_value + 1):
                f.write(str(i) + "\n")
            
            f.close()
        
        
rule divide_by_gene_tsv_files:
    input:
        file_list = [os.path.join(scratch_dir, "kl_input/enhancer_module/" + chrom +".tsv") for chrom in chrom_set]
    output:
        os.path.join(scratch_dir, "kl_input/enhancer_module/divided/gene_{gene}.tsv")
    run:
        with Client() as client:
            print(input.file_list)
            rate = dd.read_csv(input.file_list, sep = "\t", dtype={'gene': 'int'})
            
            rate_gene = rate[rate["gene"] == int(wildcards.gene)]
            
            rate_gene.to_csv(output[0], sep = "\t", index = None, single_file = True)
            
rule merge_tsv_files:
    input:
        file_list = [os.path.join(scratch_dir, "kl_input/enhancer_module/divided/gene_" + str(gene) +".tsv") for gene in gene_positive_set]
    output:
        os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants.tsv")
    run:
        with Client() as client:
            rate = dd.read_csv(input.file_list, sep = "\t", dtype={'gene': 'int'})
            
            min_value = rate["gene"].min()
            print(min_value)
            
            rate["gene"] = rate["gene"] - min_value # set everything to 0
            
            rate.to_csv(output[0], sep = "\t", index = None, single_file = True)
            
rule random_sample:
    input:
        os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants.tsv")
    output:
        os.path.join(scratch_dir, "kl_input/enhancer_module/whole_genome_gene_variants_frac_{fraction}.tsv")
    run:
        with Client() as client:
            rate = dd.read_csv(input[0], sep = "\t", dtype={'mu_index': 'int', 'Freq_bin': 'float', 'gene': 'int'})
            
            sample = rate.sample(frac = float(wildcards.fraction))
            
            sample = sample.sort_values(by = "gene")
                        
            sample.to_csv(output[0], sep = "\t", index = None, single_file = True)
            
rule get_length:
    input:
        os.path.join(scratch_dir, "kl_input/enhancer_module/{header}.tsv")
    output:
        os.path.join(scratch_dir, "kl_input/enhancer_module/{header}_length.txt")
    run:
        with Client() as client:
            rate = dd.read_csv(input[0], sep = "\t", dtype={'gene': 'int'})
            
            length = len(rate)
            n_genes = len(rate["gene"].unique())
            
            f = open(output[0], "w")
            
            f.write(str(length) + "\n")
            f.write(str(n_genes) + "\n")
            
            f.close()
                
# ##################### For running KL analysis #############################
        
rule run_KL_enhancer_module:
    input:
        variants = os.path.join(scratch_dir, "kl_input/enhancer_module/{header}.tsv"),
        length_file = os.path.join(scratch_dir, "kl_input/enhancer_module/{header}_length.txt"),
        neutral_sfs = KL_data_dir + "/neutral_SFS_5bins.tsv"
    output:
        os.path.join(KL_data_dir, "raklette_output/kl_gene/enhancer_module/{header}_epoch_{epoch}.pkl")
    run:            
        input_filename = input.variants
        output_filename = output[0]
        neutral_sfs_filename = input.neutral_sfs
        
        df = pd.read_csv(input.length_file, sep = "\t", header = None)
        nb_samples = df[0][0]
        n_genes = df[0][1]
        
        with open(input.variants) as f:
            first_line = f.readline()
        header = first_line.split("\t")
            
        chunksize = 100000

        print("number of chunks " + str(nb_samples/chunksize))

        dataset = TSVDataset(input_filename, chunksize=chunksize, nb_samples = nb_samples, header_all = header, features = header)
        loader = DataLoader(dataset, batch_size=10, num_workers=1, shuffle=False)
        
        n_covs = 0
        num_epochs = int(wildcards.epoch)
        
        #now with checkpoints
        run_raklette(loader, n_covs, n_genes, num_epochs, neutral_sfs_filename, output_filename)
        
        
            
        