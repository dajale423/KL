import os
import sys
import glob
import numpy as np
import pandas as pd
import math
import sys
import random
import pickle
import dask.dataframe as dd
from dask.distributed import Client, LocalCluster

import csv

sys.path.insert(0,'/home/djl34/lab_pd/bin')
import genomic

pd_data_dir = "/home/djl34/lab_pd/data"
KL_data_dir = "/home/djl34/lab_pd/kl/data"
scratch_dir = "/n/scratch3/users/d/djl34"

base_set = ["A", "C", "T", "G"]
chrom_set = [str(x) for x in range(1, 23)]
# chrom_set = ["22"]

wildcard_constraints:
    chrom="\d+"
    
rule all:
    input:
        [os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr" + chrom +".vcf.bgz") for chrom in chrom_set],
        [os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr" + chrom +".vcf.bgz.tbi") for chrom in chrom_set],
        [os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr" + chrom +".tsv") for chrom in chrom_set],
        [os.path.join(pd_data_dir, "gnomadv3.1.2/AC/" + chrom + "/_metadata") for chrom in chrom_set],
        os.path.join(scratch_dir, "downloads/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz"),
        os.path.join(scratch_dir, "downloads/gnomad.genomes.r3.0.1.coverage.summary.tsv"),
        [os.path.join(pd_data_dir, "gnomadv3.1.2/gnomad.genomes.r3.0.1.coverage.summary.chr" + chrom +".tsv") for chrom in chrom_set],
#         os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP.bw"),
#         [os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP_chr" + chrom +".wig") for chrom in chrom_set],
        os.path.join(scratch_dir, "downloads/epimap/personal.broadinstitute.org/cboix/epimap/ChromHMM/observed_aux_18_hg38/CALLS/BSS00001_18_CALLS_segments.bed.gz")        

        

# http://genetics.bwh.harvard.edu/downloads/Vova/Roulette/        

########################################## get gnomAD #######################################################
rule download_gnomad_v3:
    input:
    output:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr{chrom}.vcf.bgz")
    shell:
        "wget -P /n/scratch3/users/d/djl34/downloads/ https://storage.googleapis.com/gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.sites.chr{wildcards.chrom}.vcf.bgz"
        
rule download_gnomad_v3_tbi:
    input:
    output:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr{chrom}.vcf.bgz.tbi")
    shell:
        "wget -P /n/scratch3/users/d/djl34/downloads/ https://storage.googleapis.com/gcp-public-data--gnomad/release/3.1.2/vcf/genomes/gnomad.genomes.v3.1.2.sites.chr{wildcards.chrom}.vcf.bgz.tbi"
        
rule download_gnomad_v3_cov:
    input:
    output:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz")
    shell:
        "wget -P /n/scratch3/users/d/djl34/downloads/ https://storage.googleapis.com/gcp-public-data--gnomad/release/3.0.1/coverage/genomes/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz"
        
rule gnomAD_v3_to_tsv:
    input:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr{chrom}.vcf.bgz")
    output:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr{chrom}.tsv")
    shell:        
        "bcftools query -f '%CHROM\t%POS\t%REF\t%ALT\t%FILTER\t%AC\t%AN\t%AF\n' {input} > {output}"

rule filter_gnomAD_v3_to_tsv:
    input:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.v3.1.2.sites.chr{chrom}.tsv")
    output:
        os.path.join(pd_data_dir, "gnomadv3.1.2/AC/{chrom}/_metadata")
    run:
        with Client() as client:
            header = ["Chrom","Pos", "Allele_ref", "Allele", "Filter", "AC", "AN", "AF"]
            base_set = ["A", "C", "T", "G"]
            
            df = dd.read_csv(input[0], sep = "\t", names = header, dtype={'AF': 'object'})
            
            df = df[(df["Allele_ref"].isin(base_set)) & df["Allele"].isin(base_set)]
            
            df = df.repartition(partition_size="1GB")
            
            df.to_parquet("/".join(output[0].split("/")[:-1]), write_index = False, compression = "gzip", write_metadata_file = True)
            
rule unzip_gnomad_v3_cov:
    input:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.r3.0.1.coverage.summary.tsv.bgz")
    output:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.r3.0.1.coverage.summary.tsv")
    shell:
        "gunzip -c {input} > {output}"
        
rule gnomad_v3_cov_split_by_chrom:
    input:
        os.path.join(scratch_dir, "downloads/gnomad.genomes.r3.0.1.coverage.summary.tsv")
    output:
        os.path.join(pd_data_dir, "gnomadv3.1.2/gnomad.genomes.r3.0.1.coverage.summary.chr{chrom}.tsv")
    run:
        with Client() as client:
            df = dd.read_csv(input[0], sep = "\t")
            df["Chrom"] = df["locus"].str.split(":", expand = True, n = 1)[0]
            df["Pos"] = df["locus"].str.split(":", expand = True, n = 1)[1]

#             df["Chrom"] = df["Chrom"].astype(int)
            df["Pos"] = df["Pos"].astype(int)
            
            df = df[df["Chrom"] == "chr" + wildcards.chrom]
            
            df.to_csv(output[0], index = False, sep = "\t", single_file = True)       

########################################## get zoonomia #######################################################
        
rule download_zoonomia_phylop:
    input:
    output:
        os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP.bw")
    shell:
        "wget -P /n/scratch3/users/d/djl34/zoonomia/ https://hgdownload.soe.ucsc.edu/goldenPath/hg38/cactus241way/cactus241way.phyloP.bw"
        
rule bigwig_to_wig:
    input:
        os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP.bw")
    output:
        os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP.wig")
    shell:
        "bigWigToWig {input} {output}"
        
rule filter_low_quality_files:
    input:
        os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP.wig")
    output:
        os.path.join(scratch_dir, "zoonomia/cactus241way.phyloP_chr{chrom}.wig")
    run:
        f_in = open(input[0], "rt")
        in_reader = csv.reader(f_in, delimiter=" ")
        
        f_out = open(output[0], "wt", newline="")
        out_writer = csv.writer(f_out, delimiter="\t", lineterminator="\n")
        
        start = False

        for row in in_reader:
            if start:
                if row[0] == "fixedStep":
                    if row[1] == "chrom=chr" + wildcards.chrom:
                        line = int(row[2].split("=")[1])
                    else:
                        break
                else:
                    out_writer.writerow([line, row[0]])
                    line += 1
            else:                
                if row[0] == "fixedStep":
                    if row[1] == "chrom=chr" + wildcards.chrom:
                        start = True
                        line = int(row[2].split("=")[1])
                        
        f_out.close()

########################################## get Boix et al. chromhmm #######################################################

rule download_chromhmm:
    input:
    output:
        os.path.join(scratch_dir, "downloads/epimap/personal.broadinstitute.org/cboix/epimap/ChromHMM/observed_aux_18_hg38/CALLS/BSS00001_18_CALLS_segments.bed.gz")
    shell:
        "wget -P /n/scratch3/users/d/djl34/downloads/epimap/ --recursive --no-parent https://personal.broadinstitute.org/cboix/epimap/ChromHMM/observed_aux_18_hg38/CALLS/"
            
