{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5700c15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pyro\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, '/home/djl34/lab_pd/kl/git/KL')\n",
    "\n",
    "import raklette_updated\n",
    "\n",
    "####################################################\n",
    "# Create Dataset\n",
    "####################################################\n",
    "class TSVDataset(Dataset):\n",
    "    def __init__(self, path, chunksize, nb_samples, header_all, features):\n",
    "        self.path = path\n",
    "        self.chunksize = chunksize\n",
    "        self.len = nb_samples // self.chunksize\n",
    "        self.header = header_all\n",
    "        self.features = features\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = next(\n",
    "            pd.read_csv(\n",
    "                self.path,\n",
    "                sep = \"\\t\",\n",
    "                skiprows=index * self.chunksize + 1,  #+1, since we skip the header\n",
    "                chunksize=self.chunksize,\n",
    "                names=self.header))\n",
    "        \n",
    "        x = x[self.features]\n",
    "        x[\"e_module\"] = x[\"e_module\"] + 1\n",
    "        x = torch.from_numpy(x.values)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "KL_data_dir = \"/home/djl34/lab_pd/kl/data/\"\n",
    "scratch_dir = \"/n/scratch3/users/d/djl34/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9265f8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sfs = pd.read_csv(KL_data_dir + \"neutral_SFS_5bins.tsv\", sep = \"\\t\")\n",
    "\n",
    "bin_columns = []\n",
    "\n",
    "for i in range(5):\n",
    "    bin_columns.append(str(i) + \"_bin\")\n",
    "\n",
    "neutral_sfs = torch.tensor(sfs[bin_columns].values)\n",
    "\n",
    "mu_ref = torch.tensor(sfs[\"mu\"].values)\n",
    "\n",
    "df = pd.read_csv(scratch_dir + \"kl_input/enhancer_module/22.tsv\", sep = \"\\t\")\n",
    "\n",
    "nb_samples = len(df)\n",
    "header = df.columns\n",
    "\n",
    "dataset = TSVDataset(scratch_dir + \"kl_input/enhancer_module/22.tsv\", chunksize=100000, nb_samples = nb_samples, header_all = header, features = header)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False)\n",
    "\n",
    "# df = df.sort_values(\"e_module\")\n",
    "\n",
    "# df[\"e_module\"] = df[\"e_module\"] + 1\n",
    "\n",
    "# mu_vals = torch.tensor(df[\"mu_index\"].values)\n",
    "# gene_ids = torch.tensor(df[\"e_module\"].values)\n",
    "# gene_ids = gene_ids.type(torch.LongTensor)\n",
    "# sample_sfs = torch.tensor(df[\"Freq_bin\"].values)\n",
    "\n",
    "# covariates = torch.tensor([1]*len(mu_vals))\n",
    "# covariates = covariates.unsqueeze(0).transpose(0,1).type(torch.FloatTensor)\n",
    "\n",
    "#define variables\n",
    "#define neut_sfs_full, mu_vals, gene_ids, covariates\n",
    "# n_covs = covariates.shape[-1]          # number of covariates included\n",
    "# n_genes = len(torch.unique(gene_ids)) + 1  # number of genes\n",
    "\n",
    "n_genes = len(df[\"e_module\"].unique()) + 1\n",
    "n_covs = 0\n",
    "\n",
    "# n_covs = 1\n",
    "# n_genes = 3\n",
    "n_bins = len(neutral_sfs[1]) - 1\n",
    "\n",
    "#define model and guide\n",
    "KL = raklette_updated.raklette(neutral_sfs, n_bins, mu_ref, n_covs, n_genes)\n",
    "model = KL.model\n",
    "guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "\n",
    "#run inference\n",
    "pyro.clear_param_store()\n",
    "# run SVI\n",
    "adam = pyro.optim.Adam({\"lr\":0.005})\n",
    "elbo = pyro.infer.Trace_ELBO(num_particles=1, vectorize_particles=True)\n",
    "svi = pyro.infer.SVI(model, guide, adam, elbo)\n",
    "losses = []\n",
    "\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2099e5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu_index</th>\n",
       "      <th>Freq_bin</th>\n",
       "      <th>e_module</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>887</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mu_index  Freq_bin  e_module\n",
       "0        75         0      -1.0\n",
       "1        86         1      -1.0\n",
       "2       887         4      -1.0\n",
       "3       253         0      -1.0\n",
       "4       240         0      -1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a51cdda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77201997"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c17e506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f08c6f4be50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d417b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, data in enumerate(loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66cf6992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100000, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bebbb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:, :, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58d9874d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,:,0].reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "acae7808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 4.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff406791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ba2ba51",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_815/1404713150.py\", line 34, in __getitem__\n    x = torch.from_numpy(x.data.values)\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/pandas/core/generic.py\", line 5907, in __getattr__\n    return object.__getattribute__(self, name)\nAttributeError: 'DataFrame' object has no attribute 'data'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Take a gradient step for each mini-batch in the dataset\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m      6\u001b[0m         mu_vals \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmu_index\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1402\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/kl/lib/python3.10/site-packages/torch/_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 461\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_815/1404713150.py\", line 34, in __getitem__\n    x = torch.from_numpy(x.data.values)\n  File \"/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/pandas/core/generic.py\", line 5907, in __getattr__\n    return object.__getattribute__(self, name)\nAttributeError: 'DataFrame' object has no attribute 'data'\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Take a gradient step for each mini-batch in the dataset\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        loss = svi.step(data[:,:,0].reshape(-1), data[:,:,2].reshape(-1), None, data[:,:,1].reshape(-1))\n",
    "#         if y is not None:\n",
    "#             y = y.type_as(x)\n",
    "#         loss = svi.step(x, y)\n",
    "        losses.append(loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a63105",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f073e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
