{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad947aa",
   "metadata": {},
   "source": [
    "## Run KL analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0907441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/djl34/.conda/envs/kl/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "from pyro.nn import PyroModule\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "sys.path.insert(0, '/home/djl34/lab_pd/kl/git/KL')\n",
    "import raklette_updated\n",
    "\n",
    "sys.path.insert(0, '/home/djl34/lab_pd/kl/git/KL/kl_gene')\n",
    "from raklette_gene import run_raklette\n",
    "\n",
    "\n",
    "KL_data_dir = \"/home/djl34/lab_pd/kl/data\"\n",
    "scratch_dir = \"/n/scratch3/users/d/djl34\"\n",
    "\n",
    "base_set = [\"A\", \"C\", \"T\", \"G\"]\n",
    "chrom_set = [str(x) for x in range(1, 23)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5826bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSVDataset(Dataset):\n",
    "    def __init__(self, path, chunksize, nb_samples, header_all, features):\n",
    "        self.path = path\n",
    "        self.chunksize = chunksize\n",
    "        self.len = nb_samples // self.chunksize\n",
    "        self.header = header_all\n",
    "        self.features = features\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = next(\n",
    "            pd.read_csv(\n",
    "                self.path,\n",
    "                sep = \"\\t\",\n",
    "                skiprows=index * self.chunksize + 1,  #+1, since we skip the header\n",
    "                chunksize=self.chunksize,\n",
    "                names=self.header))\n",
    "\n",
    "        x = x[self.features]\n",
    "        x = torch.from_numpy(x.values)\n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f785611",
   "metadata": {},
   "source": [
    "## load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56954533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done reading\n",
      "number of chunks 772.01997\n"
     ]
    }
   ],
   "source": [
    "input_filename = os.path.join(scratch_dir, \"kl_input/enhancer_module/22.tsv\")\n",
    "output_filename = os.path.join(KL_data_dir, \"raklette_output/kl_gene/enhancer_module/chr22_noncoding.tsv\")\n",
    "neutral_sfs_filename = neutral_sfs = KL_data_dir + \"/neutral_SFS_5bins.tsv\"\n",
    "\n",
    "# input_filename = os.path.join(scratch_dir, \"kl_input/enhancer_module/gene.tsv\")\n",
    "# output_filename = os.path.join(KL_data_dir, \"raklette_output/kl_gene/enhancer_module/whole_genome_noncoding.tsv\")\n",
    "\n",
    "\n",
    "with Client() as client:\n",
    "    df = dd.read_csv(input_filename, sep = \"\\t\")\n",
    "    nb_samples = len(df)\n",
    "    header = df.columns\n",
    "    n_genes = len(df[\"gene\"].unique()) + 1\n",
    "    del df\n",
    "    print(\"done reading\")\n",
    "\n",
    "chunksize = 100000\n",
    "dataset = TSVDataset(input_filename, chunksize=chunksize, nb_samples = nb_samples, header_all = header, features = header)\n",
    "\n",
    "print(\"number of chunks \" + str(nb_samples/chunksize))\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, num_workers=1, shuffle=False)\n",
    "\n",
    "n_covs = 0\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253df319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running raklette\n"
     ]
    }
   ],
   "source": [
    "print(\"running raklette\")\n",
    "\n",
    "# read neutral sfs\n",
    "sfs = pd.read_csv(neutral_sfs_filename, sep = \"\\t\")\n",
    "bin_columns = []\n",
    "for i in range(5):\n",
    "    bin_columns.append(str(i) + \"_bin\")\n",
    "neutral_sfs = torch.tensor(sfs[bin_columns].values)\n",
    "mu_ref = torch.tensor(sfs[\"mu\"].values)\n",
    "\n",
    "n_bins = len(neutral_sfs[1]) - 1\n",
    "\n",
    "#define model and guide\n",
    "KL = raklette_updated.raklette(neutral_sfs, n_bins, mu_ref, n_covs, n_genes)\n",
    "model = KL.model\n",
    "guide = pyro.infer.autoguide.AutoNormal(model)\n",
    "\n",
    "#run inference\n",
    "pyro.clear_param_store()\n",
    "# run SVI\n",
    "adam = pyro.optim.Adam({\"lr\":0.005})\n",
    "elbo = pyro.infer.Trace_ELBO(num_particles=1, vectorize_particles=True)\n",
    "svi = pyro.infer.SVI(model, guide, adam, elbo)\n",
    "losses = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5375408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3770883.531110159\n",
      "Finished training!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Take a gradient step for each mini-batch in the dataset\n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        gene_ids = data[:,:,2].reshape(-1)\n",
    "        gene_ids = gene_ids.type(torch.LongTensor)\n",
    "\n",
    "        mu_vals = data[:,:,0].reshape(-1)\n",
    "        mu_vals = mu_vals.type(torch.LongTensor)\n",
    "\n",
    "        loss = svi.step(mu_vals, gene_ids, None, data[:,:,1].reshape(-1))\n",
    "        losses.append(loss)\n",
    "        \n",
    "\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(batch_idx)\n",
    "            print(loss)\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Finished training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5391150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3783954.6413213485"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "289c3862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3783954.6413213485\n"
     ]
    }
   ],
   "source": [
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45369ae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "param() missing 1 required positional argument: 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pyro\u001b[38;5;241m.\u001b[39mparam()\n",
      "\u001b[0;31mTypeError\u001b[0m: param() missing 1 required positional argument: 'name'"
     ]
    }
   ],
   "source": [
    "pyro.param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf87537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
