{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bad947aa",
   "metadata": {},
   "source": [
    "### Here, I will try to apply bayesian linear regression (http://pyro.ai/examples/bayesian_regression.html) to logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c97ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as ssp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions.constraints as constraints\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from pyro.nn import PyroModule\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, SGD\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "torch.set_default_dtype(torch.double) # this was necessary on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d6bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logistic_dataset(N, p=1, noise_std=0.01):\n",
    "    X = np.random.randn(N, p)\n",
    "    \n",
    "    w = np.random.randn(p)\n",
    "    w += 2 * np.sign(w)\n",
    "\n",
    "    y = np.round(ssp.expit(np.matmul(X, w) \n",
    "                           + np.repeat(1, N) \n",
    "                           + np.random.normal(0, noise_std, size=N)))\n",
    "    y = y.reshape(N, 1)\n",
    "    X, y = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "    data = torch.cat((X, y), 1)\n",
    "    assert data.shape == (N, p + 1)\n",
    "    return X, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5e91fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.nn import PyroSample\n",
    "\n",
    "class BayesianLogisticRegression(PyroModule):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, 1)\n",
    "        \n",
    "        #set prior\n",
    "        self.linear.weight = PyroSample(dist.Normal(0., 1.).expand([1, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0, 10.).expand([1]).to_event(1))\n",
    "        \n",
    "        self.sigmoid = PyroModule[nn.Sigmoid]()\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        \n",
    "        model_output = self.sigmoid(self.linear(x)).squeeze(-1)\n",
    "        \n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "                        \n",
    "            obs = pyro.sample(\"obs\", \n",
    "                              dist.Bernoulli(probs=model_output), #is this logits or probs?\n",
    "                              obs=y.squeeze())\n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "69b4283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, p = 5000, 3\n",
    "num_iterations = 1500\n",
    "\n",
    "X_data, y_data, w = build_logistic_dataset(N, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4ffd7aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "model = BayesianLogisticRegression(p)\n",
    "guide = AutoDiagonalNormal(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a7362fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "adam = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(model, guide, adam, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e9942967",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 1426.7853\n",
      "[iteration 0101] loss: 328.6124\n",
      "[iteration 0201] loss: 249.1267\n",
      "[iteration 0301] loss: 204.7029\n",
      "[iteration 0401] loss: 181.9491\n",
      "[iteration 0501] loss: 164.6745\n",
      "[iteration 0601] loss: 148.5307\n",
      "[iteration 0701] loss: 144.1651\n",
      "[iteration 0801] loss: 135.2724\n",
      "[iteration 0901] loss: 130.3960\n",
      "[iteration 1001] loss: 126.2951\n",
      "[iteration 1101] loss: 124.6198\n",
      "[iteration 1201] loss: 121.7056\n",
      "[iteration 1301] loss: 119.7456\n",
      "[iteration 1401] loss: 117.9148\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "for j in range(num_iterations):\n",
    "    # calculate the loss and take a gradient step\n",
    "    loss = svi.step(X_data, y_data)\n",
    "    if j % 100 == 0:\n",
    "        print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "120acfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.80489071 -4.72236621  2.46736118]\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b7a478d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([ 5.4775, -9.1109,  4.7039,  2.0186])\n",
      "AutoDiagonalNormal.scale tensor([0.0804, 0.1095, 0.0811, 0.0848])\n"
     ]
    }
   ],
   "source": [
    "guide.requires_grad_(False)\n",
    "\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d37d6492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear.weight': tensor([[[ 5.4775, -9.1109,  4.7039]]]),\n",
       " 'linear.bias': tensor([[2.0186]])}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guide.quantiles([0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53b52ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.66195238, -9.53256843,  4.98061528])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w * 2.0186"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3438f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
